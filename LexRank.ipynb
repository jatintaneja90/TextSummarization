{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  read files from cnn and dailymail and add them to a dictionary where key is file name and values are list of \n",
    "#  sentences in that file.\n",
    "from os import listdir,getcwd\n",
    "from os.path import isfile, join\n",
    "def readCorpus(datasetDirectoryName):\n",
    "    docSummaryDict = {}\n",
    "    docSentencesDict = {}\n",
    "    summaryline = False\n",
    "    # datasetDirectoryName = ['cnn', 'dailymail']\n",
    "    for dirName in datasetDirectoryName:\n",
    "        filepath = join(getcwd(), dirName,'stories')\n",
    "        allFiles = [f for f in listdir(filepath) if not (f.startswith('.')) and isfile(join(filepath, f))]\n",
    "        for file in allFiles:\n",
    "            filename = join(filepath, file)\n",
    "            if 'cnn' in filename:\n",
    "                fileKey = 'cnn_' + file\n",
    "            else:\n",
    "                fileKey = 'dailymail_' + file\n",
    "            for line in open(filename,'r'): \n",
    "                if line != '\\n':\n",
    "                    if '@highlight' in line:\n",
    "                        summaryline = True\n",
    "                        continue\n",
    "                    if not summaryline:\n",
    "                        if fileKey in docSentencesDict:\n",
    "                            docSentencesDict[fileKey].append(line.strip())\n",
    "                        else:\n",
    "                            docSentencesDict[fileKey] = [line.strip()]\n",
    "                    else:\n",
    "                        summaryline = False\n",
    "                        if fileKey in docSummaryDict:\n",
    "                            docSummaryDict[fileKey].append(line.strip())\n",
    "                        else:\n",
    "                            docSummaryDict[fileKey] = [line.strip()]\n",
    "    return docSentencesDict, docSummaryDict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Doc Frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  funciton to get term-document frequency\n",
    "#  docSentencesDict should be stemmed words dictionary\n",
    "#  returns you count of words appear in how many documents for idf\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "def getTermDocfrequency(docSentencesDict):\n",
    "    termDocFreqDict = Counter()\n",
    "#     each k is a unique file and v is list of sentences\n",
    "    for k in docSentencesDict:\n",
    "        v = docSentencesDict[k]\n",
    "        fileSet = None\n",
    "        for line in v:\n",
    "            lineSet = {word for word in word_tokenize(line)}\n",
    "#             print(lineSet)\n",
    "            if fileSet is None:\n",
    "                fileSet = lineSet\n",
    "            else:\n",
    "                fileSet = fileSet | lineSet\n",
    "        for word in fileSet:\n",
    "            termDocFreqDict[word] += 1\n",
    "    return termDocFreqDict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to read stop words from a text file\n",
    "def readStopWords(filename):\n",
    "    text = []\n",
    "    if(filename.endswith('txt')):\n",
    "        file = open(filename, 'r')\n",
    "        for line in file:\n",
    "            text.append(line.strip())\n",
    "        return text\n",
    "    else:\n",
    "        return None;\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "def removeStopWords(docSentencesDict):\n",
    "    returnDocSentencesDict = {}\n",
    "#     returnText = ''\n",
    " #  list of stopWords ( removed following words from list -> eight, eleven, fifteen, first, five, forty, four, nine, \n",
    "#   one, six, sixty, twelve, twenty, two, ten, )\n",
    "# http://xpo6.com/download-stop-word-list/\n",
    "    stopWordsFile = 'stop-word-list.txt'\n",
    "    stopWords = readStopWords(stopWordsFile)\n",
    "    if stopWords is None:\n",
    "        raise Exception('Couldn\\'t parse the given file. Stop Words list is empty. Please provide a text file to parse.')\n",
    "#     print(stopWords)\n",
    "    for file in docSentencesDict:\n",
    "        modifiedTextArr = []\n",
    "        textArr = docSentencesDict[file]\n",
    "        for text in textArr:\n",
    "            modifiedText = ''\n",
    "            words = word_tokenize(text)\n",
    "            for word in words:\n",
    "                if word not in stopWords:\n",
    "                    modifiedText += word + ' '\n",
    "            modifiedTextArr.append(modifiedText)\n",
    "        returnDocSentencesDict[file] = modifiedTextArr\n",
    "    return returnDocSentencesDict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This four times better previous solution \n"
     ]
    }
   ],
   "source": [
    "# print(removeStopWords('This is four times better than previous solution'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "# creating stemmed text and stemmedTextDict(for term frequency)\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "def getStemmedText(docSentencesDict):\n",
    "    returnedDocSentencesDict = {}\n",
    "    stemmedWordFrequencyDict = {}\n",
    "    ps = PorterStemmer()\n",
    "    for file in docSentencesDict:\n",
    "        modifiedTextArr = []\n",
    "        textArr = docSentencesDict[file]\n",
    "        for text in textArr:\n",
    "            stemmedText = ''\n",
    "#         text = docSentencesDict[file]\n",
    "        \n",
    "            words = word_tokenize(text)\n",
    "            for word in words:\n",
    "                stemmedWord = ps.stem(word)\n",
    "                stemmedText += stemmedWord + ' '\n",
    "                if(stemmedWordFrequencyDict.get(stemmedWord, None) == None):\n",
    "                    stemmedWordFrequencyDict[stemmedWord] =1\n",
    "                else:\n",
    "                    stemmedWordFrequencyDict[stemmedWord] += 1 \n",
    "            modifiedTextArr.append(stemmedText)\n",
    "        returnedDocSentencesDict[file] = modifiedTextArr\n",
    "    return returnedDocSentencesDict, stemmedWordFrequencyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(getStemmedText('python pythonly pythoning pythoned jatin sankar. jatin Sankar python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set downloaded using following link\n",
    "# https://cs.nyu.edu/~kcho/DMQA/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Lex Rank Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from math import pow, log, sqrt\n",
    "from nltk import word_tokenize\n",
    "def idfModifiedCosine(sentence1,sentence2, totalNumberOfDocs, termDocfreqDict):\n",
    "#     print('sentence1 is ' + sentence1)\n",
    "#     print('sentence2 is ' + sentence2)\n",
    "    sent1TFDict = Counter()\n",
    "    sent2TFDict = Counter()\n",
    "    idfDict = {}\n",
    "    wordsInbothSentences = None\n",
    "    sentence1Arr = word_tokenize(sentence1)\n",
    "    sentence2Arr = word_tokenize(sentence2)\n",
    "    for word in sentence1Arr:\n",
    "        sent1TFDict[word] += 1\n",
    "        if wordsInbothSentences is None:\n",
    "            wordsInbothSentences = {word}\n",
    "        else:\n",
    "            wordsInbothSentences = wordsInbothSentences | {word}\n",
    "        if word not in idfDict:\n",
    "#             print('calculate idf for word : ' +  word + ' ' +  str(termDocfreqDict[word]))\n",
    "            idfDict[word] = log(totalNumberOfDocs / termDocfreqDict[word])\n",
    "    for word in sentence2Arr:\n",
    "        sent2TFDict[word] += 1\n",
    "        if wordsInbothSentences is None:\n",
    "            wordsInbothSentences = {word}\n",
    "        else:\n",
    "            wordsInbothSentences = wordsInbothSentences | {word}\n",
    "        if word not in idfDict:\n",
    "#             print('calculate idf for word : ' +  word + ' ' +  str(termDocfreqDict[word]))\n",
    "            idfDict[word] = log(totalNumberOfDocs / termDocfreqDict[word])\n",
    "    num  = 0\n",
    "    denSent1 = 0\n",
    "    denSent2 = 0\n",
    "    for word in wordsInbothSentences:\n",
    "        num += sent1TFDict.get(word,0) * sent2TFDict.get(word,0) * pow(idfDict[word],2)\n",
    "        denSent1 += pow(sent1TFDict.get(word,0) * idfDict[word],2)\n",
    "        denSent2 += pow(sent2TFDict.get(word,0) * idfDict[word],2)\n",
    "#     print('denSent1 is ' + str(denSent1))\n",
    "#     print('denSent2 is ' + str(denSent2))\n",
    "    return num / (sqrt(denSent1) * sqrt(denSent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  implementing matrix Product\n",
    "import numpy as np\n",
    "def matrixProduct(matA, matB):\n",
    "    return np.matmul(matA, matB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def matrixTranspose(mat):\n",
    "    return np.transpose(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def matrixDifference(mat1,mat2):\n",
    "    return np.subtract(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pow\n",
    "# http://www.personal.soton.ac.uk/jav/soton/HELM/workbooks/workbook_30/30_4_matrx_norms.pdf\n",
    "def calculateEucledeanNorm(mat):\n",
    "    val = 0\n",
    "    for row in mat:\n",
    "        for col in range(len(row)):\n",
    "            val += pow(row[col],2)\n",
    "    return pow(val,1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  implementing power method\n",
    "def powerMethod(cosineMatrix, N, tolerance):\n",
    "    cosineMatrixTranspose = matrixTranspose(cosineMatrix)\n",
    "    initializeP = [[(1/N) for x in range(N)] for y in range(N)]\n",
    "    t = 0\n",
    "    currentP = None\n",
    "    while True:\n",
    "        if currentP is None:\n",
    "            oldP = initializeP\n",
    "        else:\n",
    "            oldP = currentP\n",
    "        t += 1\n",
    "        currentP = matrixProduct(cosineMatrixTranspose,oldP)\n",
    "        differenceMatrix = matrixDifference(currentP, oldP)\n",
    "        difference = calculateEucledeanNorm(differenceMatrix)      \n",
    "        if difference < tolerance:\n",
    "            return currentP      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # split Text into sentences\n",
    "# def SplitTextIntoSentences(text):\n",
    "#     updatedText = ''\n",
    "#     for i in range(1,len(text)):\n",
    "#         if text[i-1] == '.' and text[i] == ' ':\n",
    "#             updatedText += '\\n'\n",
    "#         else:\n",
    "#             updatedText += text[i]\n",
    "#     sentences = updatedText.split('\\n')\n",
    "#     return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lex Rank\n",
    "#  need to check from where do we get tolerance, threshold\n",
    "#  idf-modified-cosine\n",
    "#  We might get divide by zero error, need to think how to avoid that.\n",
    "\n",
    "def lexRank(sentences,threshold, tolerance, totalNumberOfDocs, termDocfreqDict):\n",
    "    n = len(sentences)\n",
    "    cosineMatrix = [[0 for x in range(n)] for y in range(n)]\n",
    "    degree = [1 for x in range(n)]\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            cosineMatrix[i][j] = idfModifiedCosine(sentences[i],sentences[j], totalNumberOfDocs, termDocfreqDict)\n",
    "            if cosineMatrix[i][j] > threshold:\n",
    "                cosineMatrix[i][j] = 1\n",
    "                degree[i] += 1\n",
    "            else:\n",
    "                cosineMatrix[i][j] = 0\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            cosineMatrix[i][j] = cosineMatrix[i][j]/degree[i]\n",
    "    L = powerMethod(cosineMatrix, n, tolerance)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands to run Lex Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# docSentencesDict = readCorpus(['Test_cnn', 'Test_dailymail'])\n",
    "# #  preprocessing\n",
    "# removedStopWordsDocSentencesDict = removeStopWords(docSentencesDict)\n",
    "# # stemmedWordFrequencyDict is not need in our implementation\n",
    "# stemmedDocSentencesDict, stemmedWordFrequencyDict = getStemmedText(removedStopWordsDocSentencesDict)\n",
    "# termDocFrequencyDict = getTermDocfrequency(stemmedDocSentencesDict)\n",
    "# totalDocs = len(docSentencesDict)\n",
    "# # testFile will be array of stemmed sentences in a test file\n",
    "# # testFile = \n",
    "#  threshold is in range of [0.1 - 0.3]\n",
    "#  very high thresholds may lose almost all of the information in a similarity matrix\n",
    "# threshold = 0.1\n",
    "#  tolerance is also consider as damping factor, range [0.1 - 0.2], research paper has taken it as 0.85\n",
    "# tolerance = 0.1\n",
    "# L = lexRank(testFile,threshold, tolerance, totalDocs, termDocFrequencyDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Questions are\n",
    "# 1) threshold value\n",
    "# 2) how will I convert L returned by lex rank to readable summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing the code on first 5 files of cnn and dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['By',\n",
       " 'Ryan Gorman',\n",
       " 'PUBLISHED:',\n",
       " '16:25 EST, 8 September 2013',\n",
       " '|',\n",
       " 'UPDATED:',\n",
       " '04:49 EST, 9 September 2013',\n",
       " 'A fan who caused outrage by appearing to taunt an alleged sexual assault victim on live television Saturday has explained his actions.',\n",
       " 'A sign held up by a University of Michigan student behind the hosts of ESPN’s College Gameday pregame show that said ‘Hi Lizzy Seeberg’ sparked outrage and appeared to taunt a girl who accused a University of Notre Dame football player of sexual assaulting her Aug 31, 2010 only to have the allegations appear to have been ignored every step of the way.',\n",
       " 'Ms Seeberg, 19, was a freshman at St Mary’s College, a small women’s only Catholic college literally across the street from the mighty Notre Dame.',\n",
       " \"I did it: The person who held up the 'Hi Lizzy Seeberg' sign wrote a letter to Deadspin detailing his reasons behind the offensive gesture\",\n",
       " 'Unable to live with the aftermath of the alleged sexual assault and Notre Dame’s refusal to even acknowledge her repeated attempts to engage the school in any manner, Ms Seeberg was found dead nine days later – the devout Catholic had overdosed on antidepressants prescribed to treat her anxiety and depression.',\n",
       " 'The name of the player was never made public and the prestigious Catholic University appeared to have swept the whole thing under the rug, until addressing it earlier this year.',\n",
       " 'Having seemingly dissipated into the ether of time, Lizzy Seeberg’s name, and alleged plight, weren’t on the minds of many people Saturday morning until a sign saying ‘Hi Lizzy Seeberg’ appeared behind College Gameday co-host Desmond Howard while discussing the Notre Dame-Michigan game being played later that day on UM’s campus.',\n",
       " 'Mr Howard won the 1991 Heisman Trophy as college football’s greatest player for that season while at the University of Michigan. He did not react on-air to the sign, nor did anyone from ESPN.',\n",
       " 'She loved country music: Pictured here at a Keith Urban concert, Lizzy Seeberg was buried in this hat after her suicide, according to reports',\n",
       " 'Reaction online to the sign was fast and furious, no one appeared to appreciate the apparent jab at a young girl who killed herself after allegedly being sexually assaulted.',\n",
       " '‘just \"Hi Lizzy Seeberg.\" So disrespectful. How does espn let that get on TV.’ (sic) tweeted @SutterHomeWhine.',\n",
       " '‘Why the HELL would someone come to @CollegeGameDay with a \"Hi Lizzy Seeburg\" sign??!? #Tasteless #NoRespect #GrowUp,’ (sic) tweeted @skrayyy.',\n",
       " \"The knee-jerk reaction ‘You stay classy, Michigan,' was also tweeted.\",\n",
       " 'Realizing his ‘statement’ was taken in a way he hadn’t intended, the student who held up the sign emailed Deadspin with an explanation.',\n",
       " 'Calling the entire ordeal ‘unacceptable,’ the letter’s author writes that it’s ‘not just unacceptable in the eyes of college football fans, or whatever, but unacceptable in the eyes of society. Notre Dame is better than this. We, as a people, are better than this.’',\n",
       " \"Referencing the open secret that is not ‘ just a systemic culture of sexual assault that puts Notre Dame in a bad light. It's also the culture of dismissal and denial that pervades this university.’\",\n",
       " \"‘Notre Dame, since day one, has spent a lot of time covering this up. From the non-statements of a priest, to the anger of President Jenkins, Notre Dame hasn't officially said anything,’ he further wrote.\",\n",
       " 'The letter writer, now hitting his stride, notes the texts that Ms Seeburg received from a friend after telling of the alleged assault.',\n",
       " \"A devout Catholic: Ms Seeberg was saving herself for marriage and said the football player's alleged demands for a lap dance left her uncomfortable and that she 'didn't know what to do'\",\n",
       " \"‘Don't do anything you would regret,’ and ’Messing with notre dame football is a bad idea.’ (sic)\",\n",
       " \"‘In short, [the sign] was done to show that she isn't forgotten, and that people do know and care about her story. Even if her school refuses to acknowledge it, there are some people out there who do,’ he wrote in the letter.\",\n",
       " 'With this being the last time Notre Dame will likely ever play at the University of Michigan’s ‘Big House,’ the student decided Saturday was the time to make his point.',\n",
       " '‘We, at Michigan, will never have a chance to say anything to this disgraceful farce of a university again, after today. So, I did. Because that is the right thing to do,’ he wrote.',\n",
       " \"‘Everyone is important, Notre Dame. Everyone has value, Notre Dame. You don't treat a victim this way, or her family this way, Notre Dame. And if you don't, you will be called out on it,’ he later added.\",\n",
       " 'The student then urges people to donate to a mission set up by Ms Seeberg’s family in her honor, as a way to remember the endless charity work she did to help Chicago’s poor and less fortunate, or to her school’s legacy fund in her name – and says he donated $25, ‘the cost of a Michigan/Notre Dame gameday t-shirt.’',\n",
       " 'Ms Seeberg’s story took months to be made public after she accused a Notre Dame football player of the sexual assault. The allegations were detailed in a police report obtained by National Catholic Reporter.',\n",
       " 'The aggressor: Notre Dame officials tried to paint her as the aggressor, saying her actions were those of a woman scorned',\n",
       " \"‘He started sucking my neck and I started crying harder,’ Ms Seeberg wrote in the report, according to NCR. ‘He pulled down my tank top by the straps. He slipped them down my shoulders and proceeded to suck and lick my right breast while holding me down on his lap by the arms,' she continued.\",\n",
       " \"'I felt his hands start to move down towards my shorts as if he was trying to unbutton them or pull them off. I was still crying at this point and felt so scared that I couldn't move,’ the report further said.\",\n",
       " 'The prosecutor declined to bring charges in the case after Ms Seeberg killed herself, which, NCR points out, is fairly common in the instance of an accuser taking their own life if they are the only witness to the alleged crime.',\n",
       " 'Ms Seeberg, according to the NCR report, was ‘both politically and personally conservative, a brand new member of the College Republicans who led her parish youth group and spoke openly about saving herself for marriage.’',\n",
       " 'Notre Dame officials moved quickly to portray her as a woman scorned, an ‘aggressive young woman who lied to get back at him for sexually rejecting her the first moment they were ever alone together,’ NCR reported.',\n",
       " 'The alleged attacker had a history of misbehaviour and a reputation as a hot head, he was even suspended from high school for misbehaviour, said NCR.',\n",
       " \"Several inconsistencies in the stories told by those involved muddled the truth, or maybe there were separate truths – each based on perception. Whatever the case, the prosecutor never pressed charges, the player was never named and moved on with his life - Lizzy Seeberg ended her's.\",\n",
       " \"No punishment: The still unnamed player involved did not miss a single game, and even played in January's National Championship for Notre Dame's Fighting Irish football team (in blue and gold)\",\n",
       " 'Where Ms Seeberg wrote that she felt ‘uncomfortable’ as she was pulled closer to her attacker while dancing in his room with others present and forced to do a lap dance, the others told investigators that ‘she was being rather forward and dancing with the young man; she was dancing for him.’',\n",
       " \"‘He told me to give him a lap dance and I didn't know what to do,’ Ms Seeburg wrote in the report.\",\n",
       " 'Notre Dame officials refused to comment on the allegations when confronted by NCR reporter Melinda Henneberger.',\n",
       " \"The same day the Chicago Tribune made Ms Seeberg’s allegations and subsequent suicide public – almost three months after the fact – Notre Dame football coach joked during a media conference call ‘that he didn't know the Tribune could afford all the reporters who were peppering him with questions about the case,’ according to NCR. Coach Kelly did not even suspend the player in question while the accusations were looked into, he played in every game, and was part of every single practice.\",\n",
       " 'The school addressed the allegations in January 2013, admitting to Huffington Post that it ‘could have acted a bit more quickly,’ but instead of apologizing for failing to even acknowledge the allegations for more than two years, the school spokesperson took the opportunity to point out that Ms Seeberg was not raped, ‘in fact, it was an allegation of touching above the waist.’',\n",
       " \"Not acceptable: The letter writer wrote that the many accusations of sexual abuse on campus are unacceptable and that someone had 'to stand up for what is right'\",\n",
       " 'Ms Seeberg’s case isn’t the first one of females accusing Notre Dame football players of sexual assault, rape or other improprieties.',\n",
       " 'One girl accused a member of the team of raping her in February 2011, the girl who drove her to the hospital after the attack claims she too was raped by a football player, NCR reported.',\n",
       " 'That girl was also urged to keep quiet in text messages sent by other players, her parents told NCR.',\n",
       " 'When told of the allegations, school administrators told the shocked parents they’d get the players to ‘knock it off,’ according to NCR.',\n",
       " 'Those are only a few of the numerous alleged attacks by Notre Dame football players, all of which can be easily found online – they are widely reported.',\n",
       " 'This is why the sign holder attempted to bring attention to what he feels is a grave injustice.',\n",
       " '‘Notre Dame is, among other things, chicken for not having the spine to even say anything to the family of a girl while they have her blood on their hands,’ the sign holder wrote in his letter to Deadspin.',\n",
       " 'Notre Dame officials were not able to be reached by MailOnline for comment.']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDocSentencesDict, testDocSummaryDict = readCorpus(['Test_cnn', 'Test_dailymail'])\n",
    "# testDocSentencesDict['dailymail_0a0a733db965c3fdf9bc2895104a1ef884a3d593.story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Despite widespread outrage, he claims the sign was meant to bring attention to her case, and that of others whose accusations of sexual assault at the University of Notre Dame have been ignored or covered up',\n",
       " 'Lizzy Seeberg, 19, was a freshman at a small Catholic college across the street from Notre Dame',\n",
       " 'Ms Seeberg had a history of anxiety and depression, and overdosed on her prescribed medication to kill herself',\n",
       " 'Notre Dame administration refused for over two years to even acknowledge the accusations, outside of A JOKE made by football coach Brian Kelly',\n",
       " 'The football player accused of the assault was never suspended, never missed a game and was allowed to attend all practices',\n",
       " \"The trip was Notre Dame's last to Michigan, the student felt the need to 'stand up for what's right'\"]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDocSummaryDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRemovedStopWordsDocSentencesDict = removeStopWords(testDocSentencesDict)\n",
    "# testRemovedStopWordsDocSentencesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStemmedDocSentencesDict, testStemmedWordFrequencyDict = getStemmedText(testRemovedStopWordsDocSentencesDict)\n",
    "# testStemmedDocSentencesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTermDocFrequencyDict = getTermDocfrequency(testStemmedDocSentencesDict)\n",
    "# for i in testTermDocFrequencyDict:\n",
    "#     if testTermDocFrequencyDict[i] == 0:\n",
    "#         print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTotalDocs = len(testDocSentencesDict)\n",
    "# testTotalDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = testStemmedDocSentencesDict['dailymail_0a0a733db965c3fdf9bc2895104a1ef884a3d593.story']\n",
    "# testFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00223214  0.00223214  0.00223214 ...,  0.00223214  0.00223214\n",
      "   0.00223214]\n",
      " [ 0.00223214  0.00223214  0.00223214 ...,  0.00223214  0.00223214\n",
      "   0.00223214]\n",
      " [ 0.00223214  0.00223214  0.00223214 ...,  0.00223214  0.00223214\n",
      "   0.00223214]\n",
      " ..., \n",
      " [ 0.00266344  0.00266344  0.00266344 ...,  0.00266344  0.00266344\n",
      "   0.00266344]\n",
      " [ 0.02237334  0.02237334  0.02237334 ...,  0.02237334  0.02237334\n",
      "   0.02237334]\n",
      " [ 0.01532171  0.01532171  0.01532171 ...,  0.01532171  0.01532171\n",
      "   0.01532171]]\n"
     ]
    }
   ],
   "source": [
    "#  threshold is in range of [0.1 - 0.3]\n",
    "#  very high thresholds may lose almost all of the information in a similarity matrix\n",
    "threshold = 0.1\n",
    "#  tolerance is also consider as damping factor, range [0.1 - 0.2], research paper has taken it as 0.85\n",
    "tolerance = 0.1\n",
    "L = lexRank(testFile,threshold, tolerance, testTotalDocs, testTermDocFrequencyDict)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
