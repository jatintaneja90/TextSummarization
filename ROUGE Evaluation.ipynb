{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# systemGenerated.txt,humanGenerated.txt\n",
    "#  reading summary from a file\n",
    "from os import listdir,getcwd\n",
    "from os.path import isfile, join\n",
    "def readResults(filename, subDirName):\n",
    "    allSentences = []\n",
    "    dirName = 'summarisation'\n",
    "    file = join(getcwd(), dirName, subDirName, filename)\n",
    "    f = open(file,'r')\n",
    "    for line in f:\n",
    "        allSentences.append(line.strip())\n",
    "    f.close()\n",
    "    return allSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemGenerated = readResults('SummryNewsFile4.txt', 'systemGenerated')\n",
    "# systemGenerated = readResults('cnn_NewsFile4.txt', 'systemGenerated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Novelty nonhuman accounts have been a Twitter staple since Sockington, a Boston-area housecat, joined the service in March 2007 on his way to 1.4 million followers. But they've been in the news again recently after one user created @olympicseat, a tongue-in-cheek response to the curiously vacant seats at Olympic venues in London. In the span of a few days, it has amassed more than 21,000 followers.\",\n",
       " '\"I figured the best way to test the waters was with a pseudonym,\" said the Burlington, Vermont, resident who asked that her name not be published to preserve the anonymity of her Twitter persona. \"I wouldn\\'t offend friends and colleagues if I didn\\'t follow them, and I could make a polite exit from Twitter when I was done poking around.\"',\n",
       " '\"I love everything about the fog,\" said the man who created @KarlTheFog in August 2010. \"I think the way it sneaks over the hills is beautiful, mysterious and even a little romantic. I love how it stops at certain points above the city, creating a wall of clouds. And having moved here from a city where it was 100-plus degrees in the summer, I was mostly excited to not be dripping in sweat for three consecutive months.\"',\n",
       " 'The man, who also requested anonymity, was inspired by @BPGlobalPR, a popular parody response to the BP oil spill in the Gulf of Mexico. Through the lens of \"Karl the Fog,\" he reports on the public\\'s feelings toward the fog and acts like a PR rep for the maligned form of weather -- with a witty bent. Karl already has more than 5,000 followers.',\n",
       " '\"[I get] lots of weather puns and haikus. My favorite tweets are when people take pictures of Karl and post them on Twitter or Instagram,\" the man said. \"Seeing so many people pick up on it and tag Karl in their pictures has been overwhelmingly cool.\"',\n",
       " \"The Orange Cone was originally a MySpace account but came to Twitter after its creator discovered the witty tweets of Bronx Zoo's Cobra, last year's famously escaped snake, and motorsports satirist @nascarcasm. Today the Orange Cone keeps a following of more than 20,000 users up to date on NASCAR happenings.\",\n",
       " '\"People notice cones in their everyday life and send pictures to me by the hundreds,\" said the man behind the Cone, who asked that his name not be used. \"I find that hilarious -- people stopping what they are doing in the real world to take a picture of an orange cone. I love it.\"',\n",
       " '\"I have a feeling, and I could be wrong, that the people that follow The Orange Cone find it to be more \\'real\\' than some of the drivers out on the track,\" its creator said. \"They can reach out and in most cases get a response. And the fact that no one knows who it is -- which means it could be anyone -- just adds to the mystery and the enjoyment.\"',\n",
       " 'Other Twitter users say that embodying nonhuman entities gives them the chance to create alter egos. \"The Cone gets to say and do the things I think we all wish we could do,\" its creator said.']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systemGenerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# humanGenerated = readResults('cnn_NewsFile4.txt', 'humanGenerated')\n",
    "humanGenerated = readResults('cnn_NewsFile4_frn.txt', 'humanGenerated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The article talks about the new age of novelty twitter accounts that have gained popularity.',\n",
       " 'Many popular accounts on twitter are based on nonhuman entities, inanimate objects or real life materials like an orange cone that everyone sees or a horse that speaks for himslef or even the fog that the people of the bay area experience.',\n",
       " 'These account gain a lot of followers because of their witty tweets which are based on common life which people can relate to.',\n",
       " 'The owners of these account say that, its a way to put forward some issues without offending anyone personally as their identity is hidden and they can speak as an inanimate object.',\n",
       " 'Common people gain lot of intrest as they can interact with an orange cone when a real life orange cone is hit by a famous racer, or they can post questions for the fog when the fog in the bay area creates commute problems.',\n",
       " 'This trend of novelty accounts has proven beneficial for both the owners as well as the common people as the ownets gain popularity and then earn by selling their merchandise and the commin people can put forward their problems and well also have some fun with their creative wity tweets.']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanGenerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "def getUnigrams(textArr):\n",
    "    text = ''.join(textArr)\n",
    "    unigrams = word_tokenize(text)\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  implementing ROGUE score\n",
    "from nltk import bigrams\n",
    "def getBigrams(textArr):\n",
    "    bigrm = list(bigrams(getUnigrams(textArr)))\n",
    "    return bigrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# systemGeneratedUnigrams = getUnigrams(systemGenerated)\n",
    "systemGeneratedBigrams = getBigrams(systemGenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# humanGeneratedUnigrams = getUnigrams(humanGenerated)\n",
    "humanGeneratedBigrams = getBigrams(humanGenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlappingBigrams = []\n",
    "for bigram in systemGeneratedBigrams:\n",
    "    if bigram in humanGeneratedBigrams:\n",
    "        overlappingBigrams.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('way', 'to'),\n",
       " ('in', 'the'),\n",
       " ('way', 'to'),\n",
       " ('about', 'the'),\n",
       " ('the', 'fog'),\n",
       " ('in', 'the'),\n",
       " ('in', 'the'),\n",
       " ('the', 'fog'),\n",
       " ('for', 'the'),\n",
       " ('witty', 'tweets'),\n",
       " ('in', 'the'),\n",
       " ('an', 'orange'),\n",
       " ('orange', 'cone'),\n",
       " ('that', 'the'),\n",
       " ('the', 'people'),\n",
       " ('of', 'the'),\n",
       " ('and', 'the'),\n",
       " ('say', 'that'),\n",
       " ('nonhuman', 'entities')]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlappingBigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rouge2 = len(overlappingBigrams)/len(humanGeneratedBigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09313725490196079"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyrouge import Rouge155\n",
    "\n",
    "# # r = Rouge155()\n",
    "# r.system_dir = './summarisation/systemGenerated'\n",
    "# r.model_dir = '/summarisation/humanGenerated'\n",
    "# r.system_filename_pattern = 'systemGenerated_1.txt'\n",
    "# r.model_filename_pattern = 'humanGenerated_1.txt'\n",
    "\n",
    "# output = r.convert_and_evaluate(\n",
    "# print(output)\n",
    "# output_dict = r.output_to_dict(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  implement LCS program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def LCS(sentence1,sentence2):\n",
    "    m = len(sentence1)\n",
    "    n = len(sentence2)\n",
    "    b = [[0 for i in range(0,n+1)] for j in range(0,m+1)]\n",
    "    c = [[0 for i in range(0,n+1)] for j in range(0,m+1)]\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if sentence1[i-1] == sentence2[j-1]:\n",
    "                c[i][j] = c[i-1][j-1]+1\n",
    "                b[i][j] = 1\n",
    "            elif c[i-1][j] >= c[i][j-1]:\n",
    "                c[i][j] = c[i-1][j]\n",
    "                b[i][j] = 2\n",
    "            else:\n",
    "                c[i][j] = c[i][j-1]\n",
    "                b[i][j] = 3\n",
    "    return c[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  should return RLCS score for now\n",
    "def LCSScore(refSummary, candidateSummary):\n",
    "    lscscore = LCS(refSummary,candidateSummary)\n",
    "#     print(lscscore)\n",
    "    RLCS = lscscore/len(refSummary)\n",
    "#     print(RLCS)\n",
    "    return RLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "count = 0\n",
    "for systemLine in systemGenerated:\n",
    "    for humanLine in humanGenerated:\n",
    "        count += 1\n",
    "        score += LCSScore(humanLine, systemLine)   \n",
    "RougeL = score/count\n",
    "#         print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5623408133720639"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RougeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SummaryQuality = (Rouge2+RougeL)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32773903413701233"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryQuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
